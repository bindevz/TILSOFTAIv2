schema_version: "1.0"
document: "PATCH 17.03 - Prompt/Context Pack Token Budgeting (Remove Hard Truncation)"
language: "en"

problem_statement:
  - "ToolCatalogContextPackProvider truncates instruction/description too aggressively (e.g., 100 chars)."
  - "Hard truncation loses critical constraints (read-only/approval/args) and increases tool misuse."
  - "Enterprise needs token-budgeted context packs with stable prioritization."

goals:
  - "Replace char-based truncation with token-based budgeting."
  - "Preserve semantics: keep 'what/when/args constraints' portion of instructions."
  - "Make limits configurable: MaxTools, MaxTotalTokens, per-tool caps."

hard_constraints:
  - "No fixed 100-char truncation."
  - "If over budget: reduce tool count first, then instruction tokens, then description tokens."
  - "Tool list ordering must be stable (prefer list, then by module/name)."

files_to_modify_or_create:
  create:
    - path: "src/TILSOFTAI.Domain/Configuration/ToolCatalogContextPackOptions.cs"
      requirements:
        - "MaxTools: int (default 40)"
        - "MaxTotalTokens: int (default 900)"
        - "MaxInstructionTokensPerTool: int (default 60)"
        - "MaxDescriptionTokensPerTool: int (default 30)"
        - "PreferTools: string[] (optional) - always include first"
  modify:
    - path: "src/TILSOFTAI.Infrastructure/Prompting/ToolCatalogContextPackProvider.cs"
      changes:
        - "Inject IOptions<ToolCatalogContextPackOptions> + token estimator + ContextPackBudgeter."
        - "Candidate list: PreferTools first, then remaining sorted by (module, toolName)."
        - "Trim by tokens using estimator (TrimToTokens)."
        - "Ensure total pack tokens <= MaxTotalTokens by dropping lowest-priority tools."
    - path: "src/TILSOFTAI.Api/Extensions/AddTilsoftAiExtensions.cs"
      changes:
        - "Bind ToolCatalogContextPackOptions and validate ranges."
    - path: "src/TILSOFTAI.Infrastructure/Prompting/ContextPackBudgeter.cs"
      changes:
        - "If token-estimator abstraction is missing, add a small adapter using existing tokenizer approximation."

implementation_steps:
  - step: "S1 - Add options"
  - step: "S2 - Implement token-aware trimming"
    detail:
      - "TrimToTokens(text,maxTokens) => keep first N tokens, append 'â€¦' if trimmed."
  - step: "S3 - Budget algorithm"
    detail:
      - "Build per-tool compact entry: name + trimmed description + trimmed instruction."
      - "Apply per-tool caps."
      - "While totalTokens > MaxTotalTokens: remove last tool."
  - step: "S4 - Safety"
    detail:
      - "Do not inline JsonSchema into context pack (too large)."

acceptance_criteria:
  - "Tool instructions are not hard-cut at 100 chars."
  - "Tool pack respects MaxTotalTokens."
  - "PreferTools are always included if enabled."

tests_required:
  - "Unit: TrimToTokens respects cap."
  - "Unit: budget removes tools when over MaxTotalTokens."
